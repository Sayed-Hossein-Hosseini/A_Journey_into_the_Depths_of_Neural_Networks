{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmAF0NhsHkgoPmZXL59LP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayed-Hossein-Hosseini/A_Journey_into_the_Depths_of_Neural_Networks/blob/master/A_Neuron_Dancing_in_Logistic_Regression_Style.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A Neuron Dancing in Logistic Regression Style**"
      ],
      "metadata": {
        "id": "RuPpZBXIQUmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "H_M6ixCMQOPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vz0-j6kYKhjk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading Dataset and Normalization**"
      ],
      "metadata": {
        "id": "giWMFWiFQlFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AW0swbhQul7",
        "outputId": "2e24b6b8-419d-453c-d283-1b7f127dce30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Relabeling Data**"
      ],
      "metadata": {
        "id": "vZZRZHsbU8gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label 0 is for airplane\n",
        "y_train = np.where(y_train == 0, 0, 1)\n",
        "y_test = np.where(y_test == 0, 0, 1)\n",
        "\n",
        "print(\"y_train:\")\n",
        "print(y_train[160:170])\n",
        "\n",
        "print(\"y_test:\")\n",
        "print(y_test[160:170])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU49hDj7U_sX",
        "outputId": "e55987ad-d74d-4bf4-9cf6-8cbc3a17500b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train:\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "y_test:\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Flatten and Reshape Images**"
      ],
      "metadata": {
        "id": "Ufm9progYmGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape images from (32, 32, 3) to (3072,)\n",
        "X_train = X_train.reshape((X_train.shape[0], -1))  # (50000, 3072)\n",
        "X_test = X_test.reshape((X_test.shape[0], -1))     # (10000, 3072)\n",
        "\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten() # (50000,  -   10000,)"
      ],
      "metadata": {
        "id": "tDhKVGCqYmTh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model**"
      ],
      "metadata": {
        "id": "-iPhRbrdrIQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Activation Function : Sigmoid and Relu**"
      ],
      "metadata": {
        "id": "mnzpvpfWrMcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation:\n",
        "    @staticmethod\n",
        "    def sigmoid(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid_derivative(a):\n",
        "        return a * (1 - a)\n",
        "\n",
        "    @staticmethod\n",
        "    def relu(z):\n",
        "        return np.maximum(0, z)\n",
        "\n",
        "    @staticmethod\n",
        "    def relu_derivative(z):\n",
        "        return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "x0QGpN9KrV1_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Neural Network**"
      ],
      "metadata": {
        "id": "20JZ6cuHxEnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dence Layer Class**"
      ],
      "metadata": {
        "id": "46o1yXDkxYBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "    def __init__(self, input_size, output_size, activation='sigmoid'):\n",
        "        self.w = np.random.randn(input_size, output_size) * 0.01\n",
        "        self.b = np.zeros((1, output_size))\n",
        "        self.activation_name = activation\n",
        "        self.z = None\n",
        "        self.a = None\n",
        "        self.input = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "        self.z = np.dot(x, self.w) + self.b\n",
        "        if self.activation_name == 'sigmoid':\n",
        "            self.a = Activation.sigmoid(self.z)\n",
        "        elif self.activation_name == 'relu':\n",
        "            self.a = Activation.relu(self.z)\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, da, lr):\n",
        "        m = self.input.shape[0]\n",
        "        if self.activation_name == 'sigmoid':\n",
        "            dz = da * Activation.sigmoid_derivative(self.a)\n",
        "        elif self.activation_name == 'relu':\n",
        "            dz = da * Activation.relu_derivative(self.z)\n",
        "\n",
        "        dw = np.dot(self.input.T, dz) / m\n",
        "        db = np.sum(dz, axis=0, keepdims=True) / m\n",
        "        da_prev = np.dot(dz, self.w.T)\n",
        "\n",
        "        self.w -= lr * dw\n",
        "        self.b -= lr * db\n",
        "\n",
        "        return da_prev"
      ],
      "metadata": {
        "id": "lKK6y_4-7nqv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Neural Network Class**"
      ],
      "metadata": {
        "id": "Ckqh4rYj8Ovl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        epsilon = 1e-8\n",
        "        return -np.mean(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))\n",
        "\n",
        "    def backward(self, y_true, y_pred, lr):\n",
        "        da = -(np.divide(y_true, y_pred + 1e-8) - np.divide(1 - y_true, 1 - y_pred + 1e-8))\n",
        "        for layer in reversed(self.layers):\n",
        "            da = layer.backward(da, lr)\n",
        "\n",
        "    def train(self, X, y, epochs=100, lr=0.1):\n",
        "        for epoch in range(epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            loss = self.compute_loss(y, y_pred)\n",
        "            self.backward(y, y_pred, lr)\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch} - Loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = self.forward(X)\n",
        "        return (y_pred >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "ca_5RsGf8RhL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main**"
      ],
      "metadata": {
        "id": "O8-Dn44Bvscx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.add(DenseLayer(3072, 1, activation='sigmoid'))\n",
        "\n",
        "model.train(X_train, y_train, epochs=1000, lr=0.01)\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "22f2XcLR8v7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}