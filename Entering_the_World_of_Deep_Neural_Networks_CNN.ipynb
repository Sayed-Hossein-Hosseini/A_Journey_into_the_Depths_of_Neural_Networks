{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmEJZTQ0w1g8niuLoforag",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayed-Hossein-Hosseini/A_Journey_into_the_Depths_of_Neural_Networks/blob/master/Entering_the_World_of_Deep_Neural_Networks_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entering the World of Deep Neural Networks CNN**"
      ],
      "metadata": {
        "id": "RnniLMx77cZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "Be4h7rum7j2U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uEFxlinH7Rxm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GPU**"
      ],
      "metadata": {
        "id": "g97QeJdBBsyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#0. Check GPU availability and device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSCxzls8Btiy",
        "outputId": "a36086b9-7c50-4670-b23e-cdb448c1d07c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameters**"
      ],
      "metadata": {
        "id": "j6cfu0Q-C6wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Hyperparameters\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "P1mLnFQmC8Rd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CIFAR-10 Data Preparation**"
      ],
      "metadata": {
        "id": "W0i9xWNXDehR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing**"
      ],
      "metadata": {
        "id": "xHmUkhhJD8L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations: Tensor Conversion and Normalization\n",
        "# Mean and Standard Deviation Values ​​for CIFAR-10 (Standard)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # مقادیر دقیق‌تر\n",
        "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # ساده‌تر، برای نرمال‌سازی به بازه [-1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "7MOYK0--Deu6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download and Load the Training Dataset**"
      ],
      "metadata": {
        "id": "Z6u5_PFOG1Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load training dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9exFrp0WE8-Q",
        "outputId": "9f87ef0d-b2dc-4500-d4f6-879ce98b999b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download and Load the Test Dataset**"
      ],
      "metadata": {
        "id": "mXaa-Wp7GulL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load the test dataset\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "-zQUXMgKGU7v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIFAR-10 Classes**"
      ],
      "metadata": {
        "id": "B1HfHxu9Hpjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 classes\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "5TTNCtqgHpwq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Display Images**"
      ],
      "metadata": {
        "id": "evrMK1SvIDMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display images\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize if normalized to [-1,1]\n",
        "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
        "    std = np.array([0.2023, 0.1994, 0.2010])\n",
        "    img = img * std[:, None, None] + mean[:, None, None]\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Show some random educational images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "AkZyS73_IDYr",
        "outputId": "3b43a2ce-11d5-4a05-d208-373f43c7459b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-d47584482e73>:7: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  img = img * std[:, None, None] + mean[:, None, None]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car   dog   truck dog  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN Model Definition**"
      ],
      "metadata": {
        "id": "dYAFaQEvJErz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        # Input: 3x32x32 (channels, height, width)\n",
        "\n",
        "        # First convolutional layer: 32 filters, kernel size 3x3, ReLU activation\n",
        "        # Output with padding=1: 32x32x32\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # First Max Pooling layer: pool size 2x2\n",
        "        # Output: 32x16x16\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Second convolutional layer: 64 filters, kernel size 3x3, ReLU activation\n",
        "        # Output with padding=1: 64x16x16\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Second Max Pooling layer: pool size 2x2\n",
        "        # Output: 64x8x8\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Flatten layer\n",
        "        # Flattened input dimensions: 64 * 8 * 8 = 4096\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # First Fully Connected layer: 128 neurons, ReLU activation\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        # Second Fully Connected layer (output layer): 10 neurons, Softmax activation\n",
        "        # Note: nn.CrossEntropyLoss combines LogSoftmax and NLLLoss internally.\n",
        "        # Therefore, if you use nn.CrossEntropyLoss, you don't need a separate Softmax layer.\n",
        "        # But if you want the output to be probabilities (e.g., for inference) or use NLLLoss, LogSoftmax is more suitable.\n",
        "        # If specifically Softmax is required, it can be applied in the forward method.\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        # self.softmax = nn.Softmax(dim=1)  # or nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.flatten(x)  # or x = x.view(-1, 64 * 8 * 8)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        # If we want the output to be probabilities directly:\n",
        "        # x = self.softmax(x)  # Typically used during inference, not during training with CrossEntropyLoss\n",
        "        # Or if using NLLLoss:\n",
        "        # x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "model = CNN(num_classes=len(classes)).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syK4zk11JME7",
        "outputId": "41d0ca81-1be4-4c78-f344-a9671377c783"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define the loss function and optimizer**"
      ],
      "metadata": {
        "id": "IHoMYlKXNk89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # This loss function includes Softmax internally\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "_X5q7Q_BNlN5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **First Structure**"
      ],
      "metadata": {
        "id": "a0_MJNXDY2kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #1. Hyperparameters\n",
        "# NUM_EPOCHS = 100\n",
        "# BATCH_SIZE = 128\n",
        "# LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "vTj8kO6ZZA2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training loop**"
      ],
      "metadata": {
        "id": "vCzNlrcQOEW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Training loop\n",
        "total_steps = len(train_loader)\n",
        "print(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()     # Zero the gradients\n",
        "        loss.backward()           # Backpropagation\n",
        "        optimizer.step()          # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    avg_epoch_loss = running_loss / total_steps\n",
        "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] completed. Average Training Loss: {avg_epoch_loss:.4f}')\n",
        "\n",
        "    # Optional: Evaluate model after each epoch\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_loss = 0\n",
        "        for images_val, labels_val in test_loader:\n",
        "            images_val = images_val.to(device)\n",
        "            labels_val = labels_val.to(device)\n",
        "\n",
        "            outputs_val = model(images_val)\n",
        "            loss_val = criterion(outputs_val, labels_val)\n",
        "            val_loss += loss_val.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs_val.data, 1)\n",
        "            total += labels_val.size(0)\n",
        "            correct += (predicted == labels_val).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "        print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy on test images: {accuracy:.2f} %')\n",
        "\n",
        "print('Finished Training.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0HLpuRTOEk7",
        "outputId": "d8446f9c-c333-4900-fea5-a66fdf4e1ba9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 100 epochs...\n",
            "Epoch [1/100], Step [100/782], Loss: 2.3107\n",
            "Epoch [1/100], Step [200/782], Loss: 2.2893\n",
            "Epoch [1/100], Step [300/782], Loss: 2.2968\n",
            "Epoch [1/100], Step [400/782], Loss: 2.3145\n",
            "Epoch [1/100], Step [500/782], Loss: 2.3151\n",
            "Epoch [1/100], Step [600/782], Loss: 2.3038\n",
            "Epoch [1/100], Step [700/782], Loss: 2.2995\n",
            "Epoch [1/100] completed. Average Training Loss: 2.3079\n",
            "Validation Loss: 2.3062, Accuracy on test images: 10.00 %\n",
            "Epoch [2/100], Step [100/782], Loss: 2.2921\n",
            "Epoch [2/100], Step [200/782], Loss: 2.3036\n",
            "Epoch [2/100], Step [300/782], Loss: 2.3388\n",
            "Epoch [2/100], Step [400/782], Loss: 2.3106\n",
            "Epoch [2/100], Step [500/782], Loss: 2.2855\n",
            "Epoch [2/100], Step [600/782], Loss: 2.3141\n",
            "Epoch [2/100], Step [700/782], Loss: 2.3138\n",
            "Epoch [2/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3073, Accuracy on test images: 10.00 %\n",
            "Epoch [3/100], Step [100/782], Loss: 2.2967\n",
            "Epoch [3/100], Step [200/782], Loss: 2.2977\n",
            "Epoch [3/100], Step [300/782], Loss: 2.2967\n",
            "Epoch [3/100], Step [400/782], Loss: 2.3095\n",
            "Epoch [3/100], Step [500/782], Loss: 2.3017\n",
            "Epoch [3/100], Step [600/782], Loss: 2.3038\n",
            "Epoch [3/100], Step [700/782], Loss: 2.3009\n",
            "Epoch [3/100] completed. Average Training Loss: 2.3069\n",
            "Validation Loss: 2.3072, Accuracy on test images: 10.00 %\n",
            "Epoch [4/100], Step [100/782], Loss: 2.3026\n",
            "Epoch [4/100], Step [200/782], Loss: 2.3034\n",
            "Epoch [4/100], Step [300/782], Loss: 2.3064\n",
            "Epoch [4/100], Step [400/782], Loss: 2.2930\n",
            "Epoch [4/100], Step [500/782], Loss: 2.3110\n",
            "Epoch [4/100], Step [600/782], Loss: 2.3319\n",
            "Epoch [4/100], Step [700/782], Loss: 2.3061\n",
            "Epoch [4/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3041, Accuracy on test images: 10.00 %\n",
            "Epoch [5/100], Step [100/782], Loss: 2.3028\n",
            "Epoch [5/100], Step [200/782], Loss: 2.2970\n",
            "Epoch [5/100], Step [300/782], Loss: 2.3252\n",
            "Epoch [5/100], Step [400/782], Loss: 2.2930\n",
            "Epoch [5/100], Step [500/782], Loss: 2.2903\n",
            "Epoch [5/100], Step [600/782], Loss: 2.3114\n",
            "Epoch [5/100], Step [700/782], Loss: 2.3078\n",
            "Epoch [5/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3113, Accuracy on test images: 9.99 %\n",
            "Epoch [6/100], Step [100/782], Loss: 2.2903\n",
            "Epoch [6/100], Step [200/782], Loss: 2.3185\n",
            "Epoch [6/100], Step [300/782], Loss: 2.2964\n",
            "Epoch [6/100], Step [400/782], Loss: 2.3041\n",
            "Epoch [6/100], Step [500/782], Loss: 2.3128\n",
            "Epoch [6/100], Step [600/782], Loss: 2.3084\n",
            "Epoch [6/100], Step [700/782], Loss: 2.3051\n",
            "Epoch [6/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3087, Accuracy on test images: 10.00 %\n",
            "Epoch [7/100], Step [100/782], Loss: 2.3037\n",
            "Epoch [7/100], Step [200/782], Loss: 2.3204\n",
            "Epoch [7/100], Step [300/782], Loss: 2.3004\n",
            "Epoch [7/100], Step [400/782], Loss: 2.3183\n",
            "Epoch [7/100], Step [500/782], Loss: 2.3111\n",
            "Epoch [7/100], Step [600/782], Loss: 2.3143\n",
            "Epoch [7/100], Step [700/782], Loss: 2.2975\n",
            "Epoch [7/100] completed. Average Training Loss: 2.3067\n",
            "Validation Loss: 2.3050, Accuracy on test images: 10.00 %\n",
            "Epoch [8/100], Step [100/782], Loss: 2.2982\n",
            "Epoch [8/100], Step [200/782], Loss: 2.3169\n",
            "Epoch [8/100], Step [300/782], Loss: 2.2969\n",
            "Epoch [8/100], Step [400/782], Loss: 2.3159\n",
            "Epoch [8/100], Step [500/782], Loss: 2.3031\n",
            "Epoch [8/100], Step [600/782], Loss: 2.2961\n",
            "Epoch [8/100], Step [700/782], Loss: 2.3061\n",
            "Epoch [8/100] completed. Average Training Loss: 2.3069\n",
            "Validation Loss: 2.3082, Accuracy on test images: 10.00 %\n",
            "Epoch [9/100], Step [100/782], Loss: 2.3078\n",
            "Epoch [9/100], Step [200/782], Loss: 2.3118\n",
            "Epoch [9/100], Step [300/782], Loss: 2.3207\n",
            "Epoch [9/100], Step [400/782], Loss: 2.3122\n",
            "Epoch [9/100], Step [500/782], Loss: 2.3152\n",
            "Epoch [9/100], Step [600/782], Loss: 2.3107\n",
            "Epoch [9/100], Step [700/782], Loss: 2.3306\n",
            "Epoch [9/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3081, Accuracy on test images: 10.00 %\n",
            "Epoch [10/100], Step [100/782], Loss: 2.3142\n",
            "Epoch [10/100], Step [200/782], Loss: 2.3128\n",
            "Epoch [10/100], Step [300/782], Loss: 2.3023\n",
            "Epoch [10/100], Step [400/782], Loss: 2.3039\n",
            "Epoch [10/100], Step [500/782], Loss: 2.3464\n",
            "Epoch [10/100], Step [600/782], Loss: 2.3126\n",
            "Epoch [10/100], Step [700/782], Loss: 2.2908\n",
            "Epoch [10/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3055, Accuracy on test images: 10.00 %\n",
            "Epoch [11/100], Step [100/782], Loss: 2.3087\n",
            "Epoch [11/100], Step [200/782], Loss: 2.3185\n",
            "Epoch [11/100], Step [300/782], Loss: 2.3167\n",
            "Epoch [11/100], Step [400/782], Loss: 2.3100\n",
            "Epoch [11/100], Step [500/782], Loss: 2.3033\n",
            "Epoch [11/100], Step [600/782], Loss: 2.3181\n",
            "Epoch [11/100], Step [700/782], Loss: 2.2880\n",
            "Epoch [11/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3110, Accuracy on test images: 10.00 %\n",
            "Epoch [12/100], Step [100/782], Loss: 2.2998\n",
            "Epoch [12/100], Step [200/782], Loss: 2.2953\n",
            "Epoch [12/100], Step [300/782], Loss: 2.2975\n",
            "Epoch [12/100], Step [400/782], Loss: 2.2959\n",
            "Epoch [12/100], Step [500/782], Loss: 2.2965\n",
            "Epoch [12/100], Step [600/782], Loss: 2.3164\n",
            "Epoch [12/100], Step [700/782], Loss: 2.3201\n",
            "Epoch [12/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3077, Accuracy on test images: 10.00 %\n",
            "Epoch [13/100], Step [100/782], Loss: 2.3066\n",
            "Epoch [13/100], Step [200/782], Loss: 2.3013\n",
            "Epoch [13/100], Step [300/782], Loss: 2.2933\n",
            "Epoch [13/100], Step [400/782], Loss: 2.3033\n",
            "Epoch [13/100], Step [500/782], Loss: 2.3051\n",
            "Epoch [13/100], Step [600/782], Loss: 2.3156\n",
            "Epoch [13/100], Step [700/782], Loss: 2.3190\n",
            "Epoch [13/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3051, Accuracy on test images: 10.00 %\n",
            "Epoch [14/100], Step [100/782], Loss: 2.3077\n",
            "Epoch [14/100], Step [200/782], Loss: 2.3097\n",
            "Epoch [14/100], Step [300/782], Loss: 2.3219\n",
            "Epoch [14/100], Step [400/782], Loss: 2.3170\n",
            "Epoch [14/100], Step [500/782], Loss: 2.3114\n",
            "Epoch [14/100], Step [600/782], Loss: 2.3076\n",
            "Epoch [14/100], Step [700/782], Loss: 2.3017\n",
            "Epoch [14/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3061, Accuracy on test images: 10.00 %\n",
            "Epoch [15/100], Step [100/782], Loss: 2.2992\n",
            "Epoch [15/100], Step [200/782], Loss: 2.2881\n",
            "Epoch [15/100], Step [300/782], Loss: 2.3044\n",
            "Epoch [15/100], Step [400/782], Loss: 2.3063\n",
            "Epoch [15/100], Step [500/782], Loss: 2.3170\n",
            "Epoch [15/100], Step [600/782], Loss: 2.3012\n",
            "Epoch [15/100], Step [700/782], Loss: 2.3055\n",
            "Epoch [15/100] completed. Average Training Loss: 2.3078\n",
            "Validation Loss: 2.3067, Accuracy on test images: 10.00 %\n",
            "Epoch [16/100], Step [100/782], Loss: 2.3185\n",
            "Epoch [16/100], Step [200/782], Loss: 2.3186\n",
            "Epoch [16/100], Step [300/782], Loss: 2.3349\n",
            "Epoch [16/100], Step [400/782], Loss: 2.3065\n",
            "Epoch [16/100], Step [500/782], Loss: 2.3055\n",
            "Epoch [16/100], Step [600/782], Loss: 2.2950\n",
            "Epoch [16/100], Step [700/782], Loss: 2.2942\n",
            "Epoch [16/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3074, Accuracy on test images: 10.00 %\n",
            "Epoch [17/100], Step [100/782], Loss: 2.2975\n",
            "Epoch [17/100], Step [200/782], Loss: 2.3056\n",
            "Epoch [17/100], Step [300/782], Loss: 2.3069\n",
            "Epoch [17/100], Step [400/782], Loss: 2.3002\n",
            "Epoch [17/100], Step [500/782], Loss: 2.3232\n",
            "Epoch [17/100], Step [600/782], Loss: 2.3055\n",
            "Epoch [17/100], Step [700/782], Loss: 2.2851\n",
            "Epoch [17/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3041, Accuracy on test images: 10.00 %\n",
            "Epoch [18/100], Step [100/782], Loss: 2.3129\n",
            "Epoch [18/100], Step [200/782], Loss: 2.3107\n",
            "Epoch [18/100], Step [300/782], Loss: 2.2891\n",
            "Epoch [18/100], Step [400/782], Loss: 2.2950\n",
            "Epoch [18/100], Step [500/782], Loss: 2.2882\n",
            "Epoch [18/100], Step [600/782], Loss: 2.2979\n",
            "Epoch [18/100], Step [700/782], Loss: 2.2956\n",
            "Epoch [18/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3069, Accuracy on test images: 10.00 %\n",
            "Epoch [19/100], Step [100/782], Loss: 2.3183\n",
            "Epoch [19/100], Step [200/782], Loss: 2.3015\n",
            "Epoch [19/100], Step [300/782], Loss: 2.2941\n",
            "Epoch [19/100], Step [400/782], Loss: 2.2999\n",
            "Epoch [19/100], Step [500/782], Loss: 2.2969\n",
            "Epoch [19/100], Step [600/782], Loss: 2.3038\n",
            "Epoch [19/100], Step [700/782], Loss: 2.2976\n",
            "Epoch [19/100] completed. Average Training Loss: 2.3064\n",
            "Validation Loss: 2.3067, Accuracy on test images: 10.00 %\n",
            "Epoch [20/100], Step [100/782], Loss: 2.3207\n",
            "Epoch [20/100], Step [200/782], Loss: 2.2944\n",
            "Epoch [20/100], Step [300/782], Loss: 2.3039\n",
            "Epoch [20/100], Step [400/782], Loss: 2.3120\n",
            "Epoch [20/100], Step [500/782], Loss: 2.2991\n",
            "Epoch [20/100], Step [600/782], Loss: 2.3238\n",
            "Epoch [20/100], Step [700/782], Loss: 2.3064\n",
            "Epoch [20/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3079, Accuracy on test images: 10.00 %\n",
            "Epoch [21/100], Step [100/782], Loss: 2.2944\n",
            "Epoch [21/100], Step [200/782], Loss: 2.3081\n",
            "Epoch [21/100], Step [300/782], Loss: 2.3034\n",
            "Epoch [21/100], Step [400/782], Loss: 2.3108\n",
            "Epoch [21/100], Step [500/782], Loss: 2.2952\n",
            "Epoch [21/100], Step [600/782], Loss: 2.3226\n",
            "Epoch [21/100], Step [700/782], Loss: 2.3182\n",
            "Epoch [21/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3072, Accuracy on test images: 10.00 %\n",
            "Epoch [22/100], Step [100/782], Loss: 2.3086\n",
            "Epoch [22/100], Step [200/782], Loss: 2.3041\n",
            "Epoch [22/100], Step [300/782], Loss: 2.3092\n",
            "Epoch [22/100], Step [400/782], Loss: 2.3009\n",
            "Epoch [22/100], Step [500/782], Loss: 2.3065\n",
            "Epoch [22/100], Step [600/782], Loss: 2.3083\n",
            "Epoch [22/100], Step [700/782], Loss: 2.2991\n",
            "Epoch [22/100] completed. Average Training Loss: 2.3069\n",
            "Validation Loss: 2.3048, Accuracy on test images: 10.00 %\n",
            "Epoch [23/100], Step [100/782], Loss: 2.3015\n",
            "Epoch [23/100], Step [200/782], Loss: 2.3320\n",
            "Epoch [23/100], Step [300/782], Loss: 2.2973\n",
            "Epoch [23/100], Step [400/782], Loss: 2.2999\n",
            "Epoch [23/100], Step [500/782], Loss: 2.3121\n",
            "Epoch [23/100], Step [600/782], Loss: 2.2994\n",
            "Epoch [23/100], Step [700/782], Loss: 2.2902\n",
            "Epoch [23/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3064, Accuracy on test images: 10.00 %\n",
            "Epoch [24/100], Step [100/782], Loss: 2.3258\n",
            "Epoch [24/100], Step [200/782], Loss: 2.3283\n",
            "Epoch [24/100], Step [300/782], Loss: 2.2973\n",
            "Epoch [24/100], Step [400/782], Loss: 2.2968\n",
            "Epoch [24/100], Step [500/782], Loss: 2.3019\n",
            "Epoch [24/100], Step [600/782], Loss: 2.3031\n",
            "Epoch [24/100], Step [700/782], Loss: 2.3082\n",
            "Epoch [24/100] completed. Average Training Loss: 2.3078\n",
            "Validation Loss: 2.3076, Accuracy on test images: 10.00 %\n",
            "Epoch [25/100], Step [100/782], Loss: 2.3083\n",
            "Epoch [25/100], Step [200/782], Loss: 2.2921\n",
            "Epoch [25/100], Step [300/782], Loss: 2.3456\n",
            "Epoch [25/100], Step [400/782], Loss: 2.3163\n",
            "Epoch [25/100], Step [500/782], Loss: 2.3094\n",
            "Epoch [25/100], Step [600/782], Loss: 2.3161\n",
            "Epoch [25/100], Step [700/782], Loss: 2.2965\n",
            "Epoch [25/100] completed. Average Training Loss: 2.3077\n",
            "Validation Loss: 2.3075, Accuracy on test images: 10.00 %\n",
            "Epoch [26/100], Step [100/782], Loss: 2.3159\n",
            "Epoch [26/100], Step [200/782], Loss: 2.3093\n",
            "Epoch [26/100], Step [300/782], Loss: 2.3086\n",
            "Epoch [26/100], Step [400/782], Loss: 2.3018\n",
            "Epoch [26/100], Step [500/782], Loss: 2.2957\n",
            "Epoch [26/100], Step [600/782], Loss: 2.2970\n",
            "Epoch [26/100], Step [700/782], Loss: 2.2994\n",
            "Epoch [26/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3058, Accuracy on test images: 10.00 %\n",
            "Epoch [27/100], Step [100/782], Loss: 2.3270\n",
            "Epoch [27/100], Step [200/782], Loss: 2.2850\n",
            "Epoch [27/100], Step [300/782], Loss: 2.2930\n",
            "Epoch [27/100], Step [400/782], Loss: 2.3165\n",
            "Epoch [27/100], Step [500/782], Loss: 2.2957\n",
            "Epoch [27/100], Step [600/782], Loss: 2.3260\n",
            "Epoch [27/100], Step [700/782], Loss: 2.2992\n",
            "Epoch [27/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3080, Accuracy on test images: 10.00 %\n",
            "Epoch [28/100], Step [100/782], Loss: 2.2994\n",
            "Epoch [28/100], Step [200/782], Loss: 2.3021\n",
            "Epoch [28/100], Step [300/782], Loss: 2.2756\n",
            "Epoch [28/100], Step [400/782], Loss: 2.2814\n",
            "Epoch [28/100], Step [500/782], Loss: 2.3010\n",
            "Epoch [28/100], Step [600/782], Loss: 2.2894\n",
            "Epoch [28/100], Step [700/782], Loss: 2.3106\n",
            "Epoch [28/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3108, Accuracy on test images: 10.00 %\n",
            "Epoch [29/100], Step [100/782], Loss: 2.3082\n",
            "Epoch [29/100], Step [200/782], Loss: 2.2958\n",
            "Epoch [29/100], Step [300/782], Loss: 2.2902\n",
            "Epoch [29/100], Step [400/782], Loss: 2.3077\n",
            "Epoch [29/100], Step [500/782], Loss: 2.3211\n",
            "Epoch [29/100], Step [600/782], Loss: 2.3056\n",
            "Epoch [29/100], Step [700/782], Loss: 2.3065\n",
            "Epoch [29/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3088, Accuracy on test images: 10.00 %\n",
            "Epoch [30/100], Step [100/782], Loss: 2.2974\n",
            "Epoch [30/100], Step [200/782], Loss: 2.3188\n",
            "Epoch [30/100], Step [300/782], Loss: 2.2993\n",
            "Epoch [30/100], Step [400/782], Loss: 2.2815\n",
            "Epoch [30/100], Step [500/782], Loss: 2.3037\n",
            "Epoch [30/100], Step [600/782], Loss: 2.3120\n",
            "Epoch [30/100], Step [700/782], Loss: 2.3019\n",
            "Epoch [30/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3066, Accuracy on test images: 10.00 %\n",
            "Epoch [31/100], Step [100/782], Loss: 2.3072\n",
            "Epoch [31/100], Step [200/782], Loss: 2.3237\n",
            "Epoch [31/100], Step [300/782], Loss: 2.3081\n",
            "Epoch [31/100], Step [400/782], Loss: 2.3049\n",
            "Epoch [31/100], Step [500/782], Loss: 2.3092\n",
            "Epoch [31/100], Step [600/782], Loss: 2.2995\n",
            "Epoch [31/100], Step [700/782], Loss: 2.3064\n",
            "Epoch [31/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3079, Accuracy on test images: 10.00 %\n",
            "Epoch [32/100], Step [100/782], Loss: 2.2955\n",
            "Epoch [32/100], Step [200/782], Loss: 2.3114\n",
            "Epoch [32/100], Step [300/782], Loss: 2.3148\n",
            "Epoch [32/100], Step [400/782], Loss: 2.3056\n",
            "Epoch [32/100], Step [500/782], Loss: 2.3024\n",
            "Epoch [32/100], Step [600/782], Loss: 2.3027\n",
            "Epoch [32/100], Step [700/782], Loss: 2.2906\n",
            "Epoch [32/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3079, Accuracy on test images: 10.00 %\n",
            "Epoch [33/100], Step [100/782], Loss: 2.3005\n",
            "Epoch [33/100], Step [200/782], Loss: 2.2792\n",
            "Epoch [33/100], Step [300/782], Loss: 2.3299\n",
            "Epoch [33/100], Step [400/782], Loss: 2.3062\n",
            "Epoch [33/100], Step [500/782], Loss: 2.3328\n",
            "Epoch [33/100], Step [600/782], Loss: 2.3142\n",
            "Epoch [33/100], Step [700/782], Loss: 2.3025\n",
            "Epoch [33/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3177, Accuracy on test images: 10.00 %\n",
            "Epoch [34/100], Step [100/782], Loss: 2.3006\n",
            "Epoch [34/100], Step [200/782], Loss: 2.3066\n",
            "Epoch [34/100], Step [300/782], Loss: 2.2959\n",
            "Epoch [34/100], Step [400/782], Loss: 2.3087\n",
            "Epoch [34/100], Step [500/782], Loss: 2.3062\n",
            "Epoch [34/100], Step [600/782], Loss: 2.3003\n",
            "Epoch [34/100], Step [700/782], Loss: 2.3042\n",
            "Epoch [34/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3065, Accuracy on test images: 10.00 %\n",
            "Epoch [35/100], Step [100/782], Loss: 2.3092\n",
            "Epoch [35/100], Step [200/782], Loss: 2.3296\n",
            "Epoch [35/100], Step [300/782], Loss: 2.3025\n",
            "Epoch [35/100], Step [400/782], Loss: 2.3069\n",
            "Epoch [35/100], Step [500/782], Loss: 2.3051\n",
            "Epoch [35/100], Step [600/782], Loss: 2.2963\n",
            "Epoch [35/100], Step [700/782], Loss: 2.3294\n",
            "Epoch [35/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3065, Accuracy on test images: 10.00 %\n",
            "Epoch [36/100], Step [100/782], Loss: 2.3140\n",
            "Epoch [36/100], Step [200/782], Loss: 2.2990\n",
            "Epoch [36/100], Step [300/782], Loss: 2.3039\n",
            "Epoch [36/100], Step [400/782], Loss: 2.3144\n",
            "Epoch [36/100], Step [500/782], Loss: 2.3314\n",
            "Epoch [36/100], Step [600/782], Loss: 2.2947\n",
            "Epoch [36/100], Step [700/782], Loss: 2.3161\n",
            "Epoch [36/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3063, Accuracy on test images: 10.00 %\n",
            "Epoch [37/100], Step [100/782], Loss: 2.3127\n",
            "Epoch [37/100], Step [200/782], Loss: 2.3095\n",
            "Epoch [37/100], Step [300/782], Loss: 2.2773\n",
            "Epoch [37/100], Step [400/782], Loss: 2.3063\n",
            "Epoch [37/100], Step [500/782], Loss: 2.2955\n",
            "Epoch [37/100], Step [600/782], Loss: 2.3172\n",
            "Epoch [37/100], Step [700/782], Loss: 2.3021\n",
            "Epoch [37/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3093, Accuracy on test images: 10.00 %\n",
            "Epoch [38/100], Step [100/782], Loss: 2.3069\n",
            "Epoch [38/100], Step [200/782], Loss: 2.3026\n",
            "Epoch [38/100], Step [300/782], Loss: 2.3141\n",
            "Epoch [38/100], Step [400/782], Loss: 2.3216\n",
            "Epoch [38/100], Step [500/782], Loss: 2.3097\n",
            "Epoch [38/100], Step [600/782], Loss: 2.2991\n",
            "Epoch [38/100], Step [700/782], Loss: 2.3105\n",
            "Epoch [38/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3126, Accuracy on test images: 10.00 %\n",
            "Epoch [39/100], Step [100/782], Loss: 2.3263\n",
            "Epoch [39/100], Step [200/782], Loss: 2.3125\n",
            "Epoch [39/100], Step [300/782], Loss: 2.2970\n",
            "Epoch [39/100], Step [400/782], Loss: 2.3012\n",
            "Epoch [39/100], Step [500/782], Loss: 2.3001\n",
            "Epoch [39/100], Step [600/782], Loss: 2.3051\n",
            "Epoch [39/100], Step [700/782], Loss: 2.3041\n",
            "Epoch [39/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3105, Accuracy on test images: 10.00 %\n",
            "Epoch [40/100], Step [100/782], Loss: 2.3081\n",
            "Epoch [40/100], Step [200/782], Loss: 2.3007\n",
            "Epoch [40/100], Step [300/782], Loss: 2.3203\n",
            "Epoch [40/100], Step [400/782], Loss: 2.3105\n",
            "Epoch [40/100], Step [500/782], Loss: 2.2821\n",
            "Epoch [40/100], Step [600/782], Loss: 2.3248\n",
            "Epoch [40/100], Step [700/782], Loss: 2.3121\n",
            "Epoch [40/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3079, Accuracy on test images: 9.99 %\n",
            "Epoch [41/100], Step [100/782], Loss: 2.3093\n",
            "Epoch [41/100], Step [200/782], Loss: 2.2937\n",
            "Epoch [41/100], Step [300/782], Loss: 2.3111\n",
            "Epoch [41/100], Step [400/782], Loss: 2.3024\n",
            "Epoch [41/100], Step [500/782], Loss: 2.3196\n",
            "Epoch [41/100], Step [600/782], Loss: 2.3121\n",
            "Epoch [41/100], Step [700/782], Loss: 2.2941\n",
            "Epoch [41/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3067, Accuracy on test images: 10.00 %\n",
            "Epoch [42/100], Step [100/782], Loss: 2.3174\n",
            "Epoch [42/100], Step [200/782], Loss: 2.3035\n",
            "Epoch [42/100], Step [300/782], Loss: 2.3087\n",
            "Epoch [42/100], Step [400/782], Loss: 2.3069\n",
            "Epoch [42/100], Step [500/782], Loss: 2.3025\n",
            "Epoch [42/100], Step [600/782], Loss: 2.2945\n",
            "Epoch [42/100], Step [700/782], Loss: 2.3027\n",
            "Epoch [42/100] completed. Average Training Loss: 2.3067\n",
            "Validation Loss: 2.3048, Accuracy on test images: 10.00 %\n",
            "Epoch [43/100], Step [100/782], Loss: 2.3018\n",
            "Epoch [43/100], Step [200/782], Loss: 2.3170\n",
            "Epoch [43/100], Step [300/782], Loss: 2.2993\n",
            "Epoch [43/100], Step [400/782], Loss: 2.3098\n",
            "Epoch [43/100], Step [500/782], Loss: 2.3114\n",
            "Epoch [43/100], Step [600/782], Loss: 2.3136\n",
            "Epoch [43/100], Step [700/782], Loss: 2.3128\n",
            "Epoch [43/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3080, Accuracy on test images: 10.00 %\n",
            "Epoch [44/100], Step [100/782], Loss: 2.3078\n",
            "Epoch [44/100], Step [200/782], Loss: 2.3207\n",
            "Epoch [44/100], Step [300/782], Loss: 2.2986\n",
            "Epoch [44/100], Step [400/782], Loss: 2.2943\n",
            "Epoch [44/100], Step [500/782], Loss: 2.2989\n",
            "Epoch [44/100], Step [600/782], Loss: 2.2977\n",
            "Epoch [44/100], Step [700/782], Loss: 2.3066\n",
            "Epoch [44/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3045, Accuracy on test images: 10.00 %\n",
            "Epoch [45/100], Step [100/782], Loss: 2.3020\n",
            "Epoch [45/100], Step [200/782], Loss: 2.3132\n",
            "Epoch [45/100], Step [300/782], Loss: 2.3239\n",
            "Epoch [45/100], Step [400/782], Loss: 2.3178\n",
            "Epoch [45/100], Step [500/782], Loss: 2.3126\n",
            "Epoch [45/100], Step [600/782], Loss: 2.3025\n",
            "Epoch [45/100], Step [700/782], Loss: 2.3096\n",
            "Epoch [45/100] completed. Average Training Loss: 2.3079\n",
            "Validation Loss: 2.3046, Accuracy on test images: 10.00 %\n",
            "Epoch [46/100], Step [100/782], Loss: 2.3157\n",
            "Epoch [46/100], Step [200/782], Loss: 2.3141\n",
            "Epoch [46/100], Step [300/782], Loss: 2.3052\n",
            "Epoch [46/100], Step [400/782], Loss: 2.3094\n",
            "Epoch [46/100], Step [500/782], Loss: 2.2862\n",
            "Epoch [46/100], Step [600/782], Loss: 2.3055\n",
            "Epoch [46/100], Step [700/782], Loss: 2.2908\n",
            "Epoch [46/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3042, Accuracy on test images: 10.00 %\n",
            "Epoch [47/100], Step [100/782], Loss: 2.3178\n",
            "Epoch [47/100], Step [200/782], Loss: 2.3156\n",
            "Epoch [47/100], Step [300/782], Loss: 2.2985\n",
            "Epoch [47/100], Step [400/782], Loss: 2.3120\n",
            "Epoch [47/100], Step [500/782], Loss: 2.3065\n",
            "Epoch [47/100], Step [600/782], Loss: 2.3187\n",
            "Epoch [47/100], Step [700/782], Loss: 2.2934\n",
            "Epoch [47/100] completed. Average Training Loss: 2.3067\n",
            "Validation Loss: 2.3064, Accuracy on test images: 10.00 %\n",
            "Epoch [48/100], Step [100/782], Loss: 2.3104\n",
            "Epoch [48/100], Step [200/782], Loss: 2.3219\n",
            "Epoch [48/100], Step [300/782], Loss: 2.3094\n",
            "Epoch [48/100], Step [400/782], Loss: 2.3058\n",
            "Epoch [48/100], Step [500/782], Loss: 2.3102\n",
            "Epoch [48/100], Step [600/782], Loss: 2.3225\n",
            "Epoch [48/100], Step [700/782], Loss: 2.2944\n",
            "Epoch [48/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3056, Accuracy on test images: 10.00 %\n",
            "Epoch [49/100], Step [100/782], Loss: 2.3064\n",
            "Epoch [49/100], Step [200/782], Loss: 2.2976\n",
            "Epoch [49/100], Step [300/782], Loss: 2.3060\n",
            "Epoch [49/100], Step [400/782], Loss: 2.3027\n",
            "Epoch [49/100], Step [500/782], Loss: 2.3336\n",
            "Epoch [49/100], Step [600/782], Loss: 2.3002\n",
            "Epoch [49/100], Step [700/782], Loss: 2.3034\n",
            "Epoch [49/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3065, Accuracy on test images: 10.00 %\n",
            "Epoch [50/100], Step [100/782], Loss: 2.3019\n",
            "Epoch [50/100], Step [200/782], Loss: 2.2953\n",
            "Epoch [50/100], Step [300/782], Loss: 2.2936\n",
            "Epoch [50/100], Step [400/782], Loss: 2.3180\n",
            "Epoch [50/100], Step [500/782], Loss: 2.3126\n",
            "Epoch [50/100], Step [600/782], Loss: 2.3156\n",
            "Epoch [50/100], Step [700/782], Loss: 2.3171\n",
            "Epoch [50/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3037, Accuracy on test images: 9.99 %\n",
            "Epoch [51/100], Step [100/782], Loss: 2.3032\n",
            "Epoch [51/100], Step [200/782], Loss: 2.2947\n",
            "Epoch [51/100], Step [300/782], Loss: 2.3008\n",
            "Epoch [51/100], Step [400/782], Loss: 2.3080\n",
            "Epoch [51/100], Step [500/782], Loss: 2.3050\n",
            "Epoch [51/100], Step [600/782], Loss: 2.2944\n",
            "Epoch [51/100], Step [700/782], Loss: 2.2997\n",
            "Epoch [51/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3069, Accuracy on test images: 10.00 %\n",
            "Epoch [52/100], Step [100/782], Loss: 2.3106\n",
            "Epoch [52/100], Step [200/782], Loss: 2.2973\n",
            "Epoch [52/100], Step [300/782], Loss: 2.2882\n",
            "Epoch [52/100], Step [400/782], Loss: 2.2941\n",
            "Epoch [52/100], Step [500/782], Loss: 2.3094\n",
            "Epoch [52/100], Step [600/782], Loss: 2.3135\n",
            "Epoch [52/100], Step [700/782], Loss: 2.2724\n",
            "Epoch [52/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3053, Accuracy on test images: 10.00 %\n",
            "Epoch [53/100], Step [100/782], Loss: 2.3259\n",
            "Epoch [53/100], Step [200/782], Loss: 2.3029\n",
            "Epoch [53/100], Step [300/782], Loss: 2.2889\n",
            "Epoch [53/100], Step [400/782], Loss: 2.3067\n",
            "Epoch [53/100], Step [500/782], Loss: 2.2967\n",
            "Epoch [53/100], Step [600/782], Loss: 2.3053\n",
            "Epoch [53/100], Step [700/782], Loss: 2.2978\n",
            "Epoch [53/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3065, Accuracy on test images: 10.00 %\n",
            "Epoch [54/100], Step [100/782], Loss: 2.3084\n",
            "Epoch [54/100], Step [200/782], Loss: 2.3020\n",
            "Epoch [54/100], Step [300/782], Loss: 2.3262\n",
            "Epoch [54/100], Step [400/782], Loss: 2.3176\n",
            "Epoch [54/100], Step [500/782], Loss: 2.2889\n",
            "Epoch [54/100], Step [600/782], Loss: 2.3203\n",
            "Epoch [54/100], Step [700/782], Loss: 2.3196\n",
            "Epoch [54/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3121, Accuracy on test images: 10.00 %\n",
            "Epoch [55/100], Step [100/782], Loss: 2.3135\n",
            "Epoch [55/100], Step [200/782], Loss: 2.2866\n",
            "Epoch [55/100], Step [300/782], Loss: 2.3116\n",
            "Epoch [55/100], Step [400/782], Loss: 2.3126\n",
            "Epoch [55/100], Step [500/782], Loss: 2.3092\n",
            "Epoch [55/100], Step [600/782], Loss: 2.3084\n",
            "Epoch [55/100], Step [700/782], Loss: 2.3112\n",
            "Epoch [55/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3044, Accuracy on test images: 10.00 %\n",
            "Epoch [56/100], Step [100/782], Loss: 2.3073\n",
            "Epoch [56/100], Step [200/782], Loss: 2.3104\n",
            "Epoch [56/100], Step [300/782], Loss: 2.2962\n",
            "Epoch [56/100], Step [400/782], Loss: 2.3047\n",
            "Epoch [56/100], Step [500/782], Loss: 2.3136\n",
            "Epoch [56/100], Step [600/782], Loss: 2.3064\n",
            "Epoch [56/100], Step [700/782], Loss: 2.2856\n",
            "Epoch [56/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3074, Accuracy on test images: 10.00 %\n",
            "Epoch [57/100], Step [100/782], Loss: 2.3051\n",
            "Epoch [57/100], Step [200/782], Loss: 2.3015\n",
            "Epoch [57/100], Step [300/782], Loss: 2.3026\n",
            "Epoch [57/100], Step [400/782], Loss: 2.3019\n",
            "Epoch [57/100], Step [500/782], Loss: 2.3200\n",
            "Epoch [57/100], Step [600/782], Loss: 2.3116\n",
            "Epoch [57/100], Step [700/782], Loss: 2.3155\n",
            "Epoch [57/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3048, Accuracy on test images: 10.00 %\n",
            "Epoch [58/100], Step [100/782], Loss: 2.3057\n",
            "Epoch [58/100], Step [200/782], Loss: 2.3036\n",
            "Epoch [58/100], Step [300/782], Loss: 2.3007\n",
            "Epoch [58/100], Step [400/782], Loss: 2.3052\n",
            "Epoch [58/100], Step [500/782], Loss: 2.3112\n",
            "Epoch [58/100], Step [600/782], Loss: 2.3049\n",
            "Epoch [58/100], Step [700/782], Loss: 2.3046\n",
            "Epoch [58/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3057, Accuracy on test images: 10.00 %\n",
            "Epoch [59/100], Step [100/782], Loss: 2.3479\n",
            "Epoch [59/100], Step [200/782], Loss: 2.3190\n",
            "Epoch [59/100], Step [300/782], Loss: 2.3073\n",
            "Epoch [59/100], Step [400/782], Loss: 2.3098\n",
            "Epoch [59/100], Step [500/782], Loss: 2.3066\n",
            "Epoch [59/100], Step [600/782], Loss: 2.3099\n",
            "Epoch [59/100], Step [700/782], Loss: 2.3110\n",
            "Epoch [59/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3060, Accuracy on test images: 10.00 %\n",
            "Epoch [60/100], Step [100/782], Loss: 2.3045\n",
            "Epoch [60/100], Step [200/782], Loss: 2.3268\n",
            "Epoch [60/100], Step [300/782], Loss: 2.3004\n",
            "Epoch [60/100], Step [400/782], Loss: 2.2996\n",
            "Epoch [60/100], Step [500/782], Loss: 2.2957\n",
            "Epoch [60/100], Step [600/782], Loss: 2.2820\n",
            "Epoch [60/100], Step [700/782], Loss: 2.2992\n",
            "Epoch [60/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3070, Accuracy on test images: 10.00 %\n",
            "Epoch [61/100], Step [100/782], Loss: 2.3193\n",
            "Epoch [61/100], Step [200/782], Loss: 2.3041\n",
            "Epoch [61/100], Step [300/782], Loss: 2.3182\n",
            "Epoch [61/100], Step [400/782], Loss: 2.2912\n",
            "Epoch [61/100], Step [500/782], Loss: 2.3046\n",
            "Epoch [61/100], Step [600/782], Loss: 2.3071\n",
            "Epoch [61/100], Step [700/782], Loss: 2.3192\n",
            "Epoch [61/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3089, Accuracy on test images: 10.00 %\n",
            "Epoch [62/100], Step [100/782], Loss: 2.3268\n",
            "Epoch [62/100], Step [200/782], Loss: 2.3114\n",
            "Epoch [62/100], Step [300/782], Loss: 2.3058\n",
            "Epoch [62/100], Step [400/782], Loss: 2.2869\n",
            "Epoch [62/100], Step [500/782], Loss: 2.3027\n",
            "Epoch [62/100], Step [600/782], Loss: 2.2869\n",
            "Epoch [62/100], Step [700/782], Loss: 2.2808\n",
            "Epoch [62/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3076, Accuracy on test images: 10.00 %\n",
            "Epoch [63/100], Step [100/782], Loss: 2.3195\n",
            "Epoch [63/100], Step [200/782], Loss: 2.3142\n",
            "Epoch [63/100], Step [300/782], Loss: 2.3048\n",
            "Epoch [63/100], Step [400/782], Loss: 2.3340\n",
            "Epoch [63/100], Step [500/782], Loss: 2.2882\n",
            "Epoch [63/100], Step [600/782], Loss: 2.3505\n",
            "Epoch [63/100], Step [700/782], Loss: 2.2971\n",
            "Epoch [63/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3075, Accuracy on test images: 10.00 %\n",
            "Epoch [64/100], Step [100/782], Loss: 2.2831\n",
            "Epoch [64/100], Step [200/782], Loss: 2.3083\n",
            "Epoch [64/100], Step [300/782], Loss: 2.2924\n",
            "Epoch [64/100], Step [400/782], Loss: 2.3043\n",
            "Epoch [64/100], Step [500/782], Loss: 2.3251\n",
            "Epoch [64/100], Step [600/782], Loss: 2.3046\n",
            "Epoch [64/100], Step [700/782], Loss: 2.3065\n",
            "Epoch [64/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3070, Accuracy on test images: 10.00 %\n",
            "Epoch [65/100], Step [100/782], Loss: 2.2978\n",
            "Epoch [65/100], Step [200/782], Loss: 2.3095\n",
            "Epoch [65/100], Step [300/782], Loss: 2.2991\n",
            "Epoch [65/100], Step [400/782], Loss: 2.2997\n",
            "Epoch [65/100], Step [500/782], Loss: 2.3030\n",
            "Epoch [65/100], Step [600/782], Loss: 2.3201\n",
            "Epoch [65/100], Step [700/782], Loss: 2.3203\n",
            "Epoch [65/100] completed. Average Training Loss: 2.3078\n",
            "Validation Loss: 2.3075, Accuracy on test images: 10.00 %\n",
            "Epoch [66/100], Step [100/782], Loss: 2.3066\n",
            "Epoch [66/100], Step [200/782], Loss: 2.3142\n",
            "Epoch [66/100], Step [300/782], Loss: 2.3286\n",
            "Epoch [66/100], Step [400/782], Loss: 2.3108\n",
            "Epoch [66/100], Step [500/782], Loss: 2.3115\n",
            "Epoch [66/100], Step [600/782], Loss: 2.3055\n",
            "Epoch [66/100], Step [700/782], Loss: 2.3145\n",
            "Epoch [66/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3077, Accuracy on test images: 10.00 %\n",
            "Epoch [67/100], Step [100/782], Loss: 2.2951\n",
            "Epoch [67/100], Step [200/782], Loss: 2.3009\n",
            "Epoch [67/100], Step [300/782], Loss: 2.3104\n",
            "Epoch [67/100], Step [400/782], Loss: 2.3047\n",
            "Epoch [67/100], Step [500/782], Loss: 2.3056\n",
            "Epoch [67/100], Step [600/782], Loss: 2.3323\n",
            "Epoch [67/100], Step [700/782], Loss: 2.3043\n",
            "Epoch [67/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3051, Accuracy on test images: 10.00 %\n",
            "Epoch [68/100], Step [100/782], Loss: 2.2976\n",
            "Epoch [68/100], Step [200/782], Loss: 2.3168\n",
            "Epoch [68/100], Step [300/782], Loss: 2.3121\n",
            "Epoch [68/100], Step [400/782], Loss: 2.3108\n",
            "Epoch [68/100], Step [500/782], Loss: 2.2965\n",
            "Epoch [68/100], Step [600/782], Loss: 2.3126\n",
            "Epoch [68/100], Step [700/782], Loss: 2.3140\n",
            "Epoch [68/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3088, Accuracy on test images: 10.00 %\n",
            "Epoch [69/100], Step [100/782], Loss: 2.3223\n",
            "Epoch [69/100], Step [200/782], Loss: 2.3127\n",
            "Epoch [69/100], Step [300/782], Loss: 2.2987\n",
            "Epoch [69/100], Step [400/782], Loss: 2.3139\n",
            "Epoch [69/100], Step [500/782], Loss: 2.3092\n",
            "Epoch [69/100], Step [600/782], Loss: 2.3156\n",
            "Epoch [69/100], Step [700/782], Loss: 2.3440\n",
            "Epoch [69/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3105, Accuracy on test images: 10.00 %\n",
            "Epoch [70/100], Step [100/782], Loss: 2.3112\n",
            "Epoch [70/100], Step [200/782], Loss: 2.2966\n",
            "Epoch [70/100], Step [300/782], Loss: 2.3096\n",
            "Epoch [70/100], Step [400/782], Loss: 2.3138\n",
            "Epoch [70/100], Step [500/782], Loss: 2.2804\n",
            "Epoch [70/100], Step [600/782], Loss: 2.3038\n",
            "Epoch [70/100], Step [700/782], Loss: 2.2953\n",
            "Epoch [70/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3073, Accuracy on test images: 10.00 %\n",
            "Epoch [71/100], Step [100/782], Loss: 2.3143\n",
            "Epoch [71/100], Step [200/782], Loss: 2.3157\n",
            "Epoch [71/100], Step [300/782], Loss: 2.2907\n",
            "Epoch [71/100], Step [400/782], Loss: 2.3002\n",
            "Epoch [71/100], Step [500/782], Loss: 2.3303\n",
            "Epoch [71/100], Step [600/782], Loss: 2.3021\n",
            "Epoch [71/100], Step [700/782], Loss: 2.2796\n",
            "Epoch [71/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3070, Accuracy on test images: 10.00 %\n",
            "Epoch [72/100], Step [100/782], Loss: 2.3042\n",
            "Epoch [72/100], Step [200/782], Loss: 2.2845\n",
            "Epoch [72/100], Step [300/782], Loss: 2.2968\n",
            "Epoch [72/100], Step [400/782], Loss: 2.3081\n",
            "Epoch [72/100], Step [500/782], Loss: 2.3222\n",
            "Epoch [72/100], Step [600/782], Loss: 2.3161\n",
            "Epoch [72/100], Step [700/782], Loss: 2.3182\n",
            "Epoch [72/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3050, Accuracy on test images: 10.00 %\n",
            "Epoch [73/100], Step [100/782], Loss: 2.2905\n",
            "Epoch [73/100], Step [200/782], Loss: 2.3289\n",
            "Epoch [73/100], Step [300/782], Loss: 2.3227\n",
            "Epoch [73/100], Step [400/782], Loss: 2.3112\n",
            "Epoch [73/100], Step [500/782], Loss: 2.3056\n",
            "Epoch [73/100], Step [600/782], Loss: 2.3175\n",
            "Epoch [73/100], Step [700/782], Loss: 2.3135\n",
            "Epoch [73/100] completed. Average Training Loss: 2.3078\n",
            "Validation Loss: 2.3058, Accuracy on test images: 10.00 %\n",
            "Epoch [74/100], Step [100/782], Loss: 2.3258\n",
            "Epoch [74/100], Step [200/782], Loss: 2.3195\n",
            "Epoch [74/100], Step [300/782], Loss: 2.3131\n",
            "Epoch [74/100], Step [400/782], Loss: 2.2971\n",
            "Epoch [74/100], Step [500/782], Loss: 2.3086\n",
            "Epoch [74/100], Step [600/782], Loss: 2.3194\n",
            "Epoch [74/100], Step [700/782], Loss: 2.2972\n",
            "Epoch [74/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3067, Accuracy on test images: 10.00 %\n",
            "Epoch [75/100], Step [100/782], Loss: 2.3438\n",
            "Epoch [75/100], Step [200/782], Loss: 2.3012\n",
            "Epoch [75/100], Step [300/782], Loss: 2.3222\n",
            "Epoch [75/100], Step [400/782], Loss: 2.3001\n",
            "Epoch [75/100], Step [500/782], Loss: 2.3057\n",
            "Epoch [75/100], Step [600/782], Loss: 2.3261\n",
            "Epoch [75/100], Step [700/782], Loss: 2.3056\n",
            "Epoch [75/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3056, Accuracy on test images: 10.00 %\n",
            "Epoch [76/100], Step [100/782], Loss: 2.3127\n",
            "Epoch [76/100], Step [200/782], Loss: 2.3055\n",
            "Epoch [76/100], Step [300/782], Loss: 2.2965\n",
            "Epoch [76/100], Step [400/782], Loss: 2.3084\n",
            "Epoch [76/100], Step [500/782], Loss: 2.3067\n",
            "Epoch [76/100], Step [600/782], Loss: 2.2990\n",
            "Epoch [76/100], Step [700/782], Loss: 2.3078\n",
            "Epoch [76/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3070, Accuracy on test images: 10.00 %\n",
            "Epoch [77/100], Step [100/782], Loss: 2.3247\n",
            "Epoch [77/100], Step [200/782], Loss: 2.3407\n",
            "Epoch [77/100], Step [300/782], Loss: 2.3334\n",
            "Epoch [77/100], Step [400/782], Loss: 2.3155\n",
            "Epoch [77/100], Step [500/782], Loss: 2.3000\n",
            "Epoch [77/100], Step [600/782], Loss: 2.3022\n",
            "Epoch [77/100], Step [700/782], Loss: 2.2918\n",
            "Epoch [77/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3091, Accuracy on test images: 10.00 %\n",
            "Epoch [78/100], Step [100/782], Loss: 2.3082\n",
            "Epoch [78/100], Step [200/782], Loss: 2.2946\n",
            "Epoch [78/100], Step [300/782], Loss: 2.2943\n",
            "Epoch [78/100], Step [400/782], Loss: 2.3136\n",
            "Epoch [78/100], Step [500/782], Loss: 2.2979\n",
            "Epoch [78/100], Step [600/782], Loss: 2.2933\n",
            "Epoch [78/100], Step [700/782], Loss: 2.3028\n",
            "Epoch [78/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3089, Accuracy on test images: 10.00 %\n",
            "Epoch [79/100], Step [100/782], Loss: 2.3092\n",
            "Epoch [79/100], Step [200/782], Loss: 2.3092\n",
            "Epoch [79/100], Step [300/782], Loss: 2.2975\n",
            "Epoch [79/100], Step [400/782], Loss: 2.3057\n",
            "Epoch [79/100], Step [500/782], Loss: 2.2982\n",
            "Epoch [79/100], Step [600/782], Loss: 2.3099\n",
            "Epoch [79/100], Step [700/782], Loss: 2.2985\n",
            "Epoch [79/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3062, Accuracy on test images: 10.00 %\n",
            "Epoch [80/100], Step [100/782], Loss: 2.3010\n",
            "Epoch [80/100], Step [200/782], Loss: 2.3054\n",
            "Epoch [80/100], Step [300/782], Loss: 2.3020\n",
            "Epoch [80/100], Step [400/782], Loss: 2.3231\n",
            "Epoch [80/100], Step [500/782], Loss: 2.2977\n",
            "Epoch [80/100], Step [600/782], Loss: 2.3528\n",
            "Epoch [80/100], Step [700/782], Loss: 2.3033\n",
            "Epoch [80/100] completed. Average Training Loss: 2.3079\n",
            "Validation Loss: 2.3060, Accuracy on test images: 10.00 %\n",
            "Epoch [81/100], Step [100/782], Loss: 2.2940\n",
            "Epoch [81/100], Step [200/782], Loss: 2.3085\n",
            "Epoch [81/100], Step [300/782], Loss: 2.3143\n",
            "Epoch [81/100], Step [400/782], Loss: 2.3140\n",
            "Epoch [81/100], Step [500/782], Loss: 2.2923\n",
            "Epoch [81/100], Step [600/782], Loss: 2.3083\n",
            "Epoch [81/100], Step [700/782], Loss: 2.3163\n",
            "Epoch [81/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3061, Accuracy on test images: 10.00 %\n",
            "Epoch [82/100], Step [100/782], Loss: 2.3050\n",
            "Epoch [82/100], Step [200/782], Loss: 2.3185\n",
            "Epoch [82/100], Step [300/782], Loss: 2.3250\n",
            "Epoch [82/100], Step [400/782], Loss: 2.3099\n",
            "Epoch [82/100], Step [500/782], Loss: 2.2820\n",
            "Epoch [82/100], Step [600/782], Loss: 2.3210\n",
            "Epoch [82/100], Step [700/782], Loss: 2.3022\n",
            "Epoch [82/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3067, Accuracy on test images: 10.00 %\n",
            "Epoch [83/100], Step [100/782], Loss: 2.3041\n",
            "Epoch [83/100], Step [200/782], Loss: 2.2982\n",
            "Epoch [83/100], Step [300/782], Loss: 2.3070\n",
            "Epoch [83/100], Step [400/782], Loss: 2.3045\n",
            "Epoch [83/100], Step [500/782], Loss: 2.3035\n",
            "Epoch [83/100], Step [600/782], Loss: 2.2989\n",
            "Epoch [83/100], Step [700/782], Loss: 2.3260\n",
            "Epoch [83/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3069, Accuracy on test images: 10.00 %\n",
            "Epoch [84/100], Step [100/782], Loss: 2.3348\n",
            "Epoch [84/100], Step [200/782], Loss: 2.3023\n",
            "Epoch [84/100], Step [300/782], Loss: 2.3026\n",
            "Epoch [84/100], Step [400/782], Loss: 2.3018\n",
            "Epoch [84/100], Step [500/782], Loss: 2.3009\n",
            "Epoch [84/100], Step [600/782], Loss: 2.2947\n",
            "Epoch [84/100], Step [700/782], Loss: 2.2764\n",
            "Epoch [84/100] completed. Average Training Loss: 2.3070\n",
            "Validation Loss: 2.3048, Accuracy on test images: 10.00 %\n",
            "Epoch [85/100], Step [100/782], Loss: 2.3066\n",
            "Epoch [85/100], Step [200/782], Loss: 2.3026\n",
            "Epoch [85/100], Step [300/782], Loss: 2.3060\n",
            "Epoch [85/100], Step [400/782], Loss: 2.2989\n",
            "Epoch [85/100], Step [500/782], Loss: 2.3123\n",
            "Epoch [85/100], Step [600/782], Loss: 2.3090\n",
            "Epoch [85/100], Step [700/782], Loss: 2.3192\n",
            "Epoch [85/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3048, Accuracy on test images: 10.00 %\n",
            "Epoch [86/100], Step [100/782], Loss: 2.3004\n",
            "Epoch [86/100], Step [200/782], Loss: 2.3252\n",
            "Epoch [86/100], Step [300/782], Loss: 2.2948\n",
            "Epoch [86/100], Step [400/782], Loss: 2.3103\n",
            "Epoch [86/100], Step [500/782], Loss: 2.3099\n",
            "Epoch [86/100], Step [600/782], Loss: 2.3208\n",
            "Epoch [86/100], Step [700/782], Loss: 2.3074\n",
            "Epoch [86/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3079, Accuracy on test images: 10.00 %\n",
            "Epoch [87/100], Step [100/782], Loss: 2.2987\n",
            "Epoch [87/100], Step [200/782], Loss: 2.3058\n",
            "Epoch [87/100], Step [300/782], Loss: 2.3117\n",
            "Epoch [87/100], Step [400/782], Loss: 2.2858\n",
            "Epoch [87/100], Step [500/782], Loss: 2.3070\n",
            "Epoch [87/100], Step [600/782], Loss: 2.3245\n",
            "Epoch [87/100], Step [700/782], Loss: 2.3213\n",
            "Epoch [87/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3051, Accuracy on test images: 10.00 %\n",
            "Epoch [88/100], Step [100/782], Loss: 2.2891\n",
            "Epoch [88/100], Step [200/782], Loss: 2.3283\n",
            "Epoch [88/100], Step [300/782], Loss: 2.3041\n",
            "Epoch [88/100], Step [400/782], Loss: 2.3172\n",
            "Epoch [88/100], Step [500/782], Loss: 2.3213\n",
            "Epoch [88/100], Step [600/782], Loss: 2.3264\n",
            "Epoch [88/100], Step [700/782], Loss: 2.3147\n",
            "Epoch [88/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3055, Accuracy on test images: 10.00 %\n",
            "Epoch [89/100], Step [100/782], Loss: 2.3015\n",
            "Epoch [89/100], Step [200/782], Loss: 2.3064\n",
            "Epoch [89/100], Step [300/782], Loss: 2.2906\n",
            "Epoch [89/100], Step [400/782], Loss: 2.2858\n",
            "Epoch [89/100], Step [500/782], Loss: 2.2887\n",
            "Epoch [89/100], Step [600/782], Loss: 2.3020\n",
            "Epoch [89/100], Step [700/782], Loss: 2.2974\n",
            "Epoch [89/100] completed. Average Training Loss: 2.3071\n",
            "Validation Loss: 2.3074, Accuracy on test images: 10.00 %\n",
            "Epoch [90/100], Step [100/782], Loss: 2.3040\n",
            "Epoch [90/100], Step [200/782], Loss: 2.3146\n",
            "Epoch [90/100], Step [300/782], Loss: 2.3017\n",
            "Epoch [90/100], Step [400/782], Loss: 2.3088\n",
            "Epoch [90/100], Step [500/782], Loss: 2.2972\n",
            "Epoch [90/100], Step [600/782], Loss: 2.3113\n",
            "Epoch [90/100], Step [700/782], Loss: 2.2950\n",
            "Epoch [90/100] completed. Average Training Loss: 2.3069\n",
            "Validation Loss: 2.3066, Accuracy on test images: 10.00 %\n",
            "Epoch [91/100], Step [100/782], Loss: 2.3116\n",
            "Epoch [91/100], Step [200/782], Loss: 2.2947\n",
            "Epoch [91/100], Step [300/782], Loss: 2.2977\n",
            "Epoch [91/100], Step [400/782], Loss: 2.2927\n",
            "Epoch [91/100], Step [500/782], Loss: 2.3294\n",
            "Epoch [91/100], Step [600/782], Loss: 2.3202\n",
            "Epoch [91/100], Step [700/782], Loss: 2.2887\n",
            "Epoch [91/100] completed. Average Training Loss: 2.3077\n",
            "Validation Loss: 2.3104, Accuracy on test images: 10.00 %\n",
            "Epoch [92/100], Step [100/782], Loss: 2.3063\n",
            "Epoch [92/100], Step [200/782], Loss: 2.2969\n",
            "Epoch [92/100], Step [300/782], Loss: 2.2996\n",
            "Epoch [92/100], Step [400/782], Loss: 2.3158\n",
            "Epoch [92/100], Step [500/782], Loss: 2.3053\n",
            "Epoch [92/100], Step [600/782], Loss: 2.2947\n",
            "Epoch [92/100], Step [700/782], Loss: 2.3098\n",
            "Epoch [92/100] completed. Average Training Loss: 2.3072\n",
            "Validation Loss: 2.3049, Accuracy on test images: 10.00 %\n",
            "Epoch [93/100], Step [100/782], Loss: 2.3293\n",
            "Epoch [93/100], Step [200/782], Loss: 2.3084\n",
            "Epoch [93/100], Step [300/782], Loss: 2.3060\n",
            "Epoch [93/100], Step [400/782], Loss: 2.2950\n",
            "Epoch [93/100], Step [500/782], Loss: 2.3088\n",
            "Epoch [93/100], Step [600/782], Loss: 2.3162\n",
            "Epoch [93/100], Step [700/782], Loss: 2.2958\n",
            "Epoch [93/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3067, Accuracy on test images: 10.00 %\n",
            "Epoch [94/100], Step [100/782], Loss: 2.3135\n",
            "Epoch [94/100], Step [200/782], Loss: 2.2768\n",
            "Epoch [94/100], Step [300/782], Loss: 2.3030\n",
            "Epoch [94/100], Step [400/782], Loss: 2.2988\n",
            "Epoch [94/100], Step [500/782], Loss: 2.3049\n",
            "Epoch [94/100], Step [600/782], Loss: 2.2948\n",
            "Epoch [94/100], Step [700/782], Loss: 2.3149\n",
            "Epoch [94/100] completed. Average Training Loss: 2.3073\n",
            "Validation Loss: 2.3052, Accuracy on test images: 10.00 %\n",
            "Epoch [95/100], Step [100/782], Loss: 2.3134\n",
            "Epoch [95/100], Step [200/782], Loss: 2.2874\n",
            "Epoch [95/100], Step [300/782], Loss: 2.3071\n",
            "Epoch [95/100], Step [400/782], Loss: 2.2864\n",
            "Epoch [95/100], Step [500/782], Loss: 2.3003\n",
            "Epoch [95/100], Step [600/782], Loss: 2.3002\n",
            "Epoch [95/100], Step [700/782], Loss: 2.2903\n",
            "Epoch [95/100] completed. Average Training Loss: 2.3074\n",
            "Validation Loss: 2.3114, Accuracy on test images: 10.00 %\n",
            "Epoch [96/100], Step [100/782], Loss: 2.3005\n",
            "Epoch [96/100], Step [200/782], Loss: 2.3003\n",
            "Epoch [96/100], Step [300/782], Loss: 2.3050\n",
            "Epoch [96/100], Step [400/782], Loss: 2.3067\n",
            "Epoch [96/100], Step [500/782], Loss: 2.3065\n",
            "Epoch [96/100], Step [600/782], Loss: 2.3022\n",
            "Epoch [96/100], Step [700/782], Loss: 2.2965\n",
            "Epoch [96/100] completed. Average Training Loss: 2.3069\n",
            "Validation Loss: 2.3088, Accuracy on test images: 10.00 %\n",
            "Epoch [97/100], Step [100/782], Loss: 2.3356\n",
            "Epoch [97/100], Step [200/782], Loss: 2.3135\n",
            "Epoch [97/100], Step [300/782], Loss: 2.3015\n",
            "Epoch [97/100], Step [400/782], Loss: 2.3213\n",
            "Epoch [97/100], Step [500/782], Loss: 2.3033\n",
            "Epoch [97/100], Step [600/782], Loss: 2.2978\n",
            "Epoch [97/100], Step [700/782], Loss: 2.3026\n",
            "Epoch [97/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3084, Accuracy on test images: 10.00 %\n",
            "Epoch [98/100], Step [100/782], Loss: 2.3047\n",
            "Epoch [98/100], Step [200/782], Loss: 2.3043\n",
            "Epoch [98/100], Step [300/782], Loss: 2.3081\n",
            "Epoch [98/100], Step [400/782], Loss: 2.3035\n",
            "Epoch [98/100], Step [500/782], Loss: 2.2938\n",
            "Epoch [98/100], Step [600/782], Loss: 2.2970\n",
            "Epoch [98/100], Step [700/782], Loss: 2.2992\n",
            "Epoch [98/100] completed. Average Training Loss: 2.3068\n",
            "Validation Loss: 2.3068, Accuracy on test images: 10.00 %\n",
            "Epoch [99/100], Step [100/782], Loss: 2.3086\n",
            "Epoch [99/100], Step [200/782], Loss: 2.3189\n",
            "Epoch [99/100], Step [300/782], Loss: 2.3082\n",
            "Epoch [99/100], Step [400/782], Loss: 2.3071\n",
            "Epoch [99/100], Step [500/782], Loss: 2.3070\n",
            "Epoch [99/100], Step [600/782], Loss: 2.3656\n",
            "Epoch [99/100], Step [700/782], Loss: 2.3040\n",
            "Epoch [99/100] completed. Average Training Loss: 2.3076\n",
            "Validation Loss: 2.3074, Accuracy on test images: 10.00 %\n",
            "Epoch [100/100], Step [100/782], Loss: 2.3371\n",
            "Epoch [100/100], Step [200/782], Loss: 2.3148\n",
            "Epoch [100/100], Step [300/782], Loss: 2.2834\n",
            "Epoch [100/100], Step [400/782], Loss: 2.2931\n",
            "Epoch [100/100], Step [500/782], Loss: 2.2990\n",
            "Epoch [100/100], Step [600/782], Loss: 2.2971\n",
            "Epoch [100/100], Step [700/782], Loss: 2.3192\n",
            "Epoch [100/100] completed. Average Training Loss: 2.3075\n",
            "Validation Loss: 2.3095, Accuracy on test images: 10.00 %\n",
            "Finished Training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Final Model Evaluation**"
      ],
      "metadata": {
        "id": "x6Ge1ZlLcL6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Final evaluation of the model on the test data\n",
        "model.eval()  # Ensure the model is in evaluation mode\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_predicted.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    final_accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the network on the 10000 test images: {final_accuracy:.2f} %')\n",
        "\n",
        "    # (Optional) Show accuracy per class\n",
        "    class_correct = list(0. for i in range(len(classes)))\n",
        "    class_total = list(0. for i in range(len(classes)))\n",
        "\n",
        "    for i in range(len(all_labels)):\n",
        "        label = all_labels[i]\n",
        "        pred = all_predicted[i]\n",
        "        if label == pred:\n",
        "            class_correct[label] += 1\n",
        "        class_total[label] += 1\n",
        "\n",
        "    print(\"\\nAccuracy per class:\")\n",
        "    for i in range(len(classes)):\n",
        "        if class_total[i] > 0:\n",
        "            print(f'Accuracy of {classes[i]:5s} : {100 * class_correct[i] / class_total[i]:.2f} %')\n",
        "        else:\n",
        "            print(f'Accuracy of {classes[i]:5s} : N/A (no samples)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aXD9IhEcUJs",
        "outputId": "87af4a41-d9c4-4704-f863-54a5a805dcf7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 10.00 %\n",
            "\n",
            "Accuracy per class:\n",
            "Accuracy of plane : 0.00 %\n",
            "Accuracy of car   : 100.00 %\n",
            "Accuracy of bird  : 0.00 %\n",
            "Accuracy of cat   : 0.00 %\n",
            "Accuracy of deer  : 0.00 %\n",
            "Accuracy of dog   : 0.00 %\n",
            "Accuracy of frog  : 0.00 %\n",
            "Accuracy of horse : 0.00 %\n",
            "Accuracy of ship  : 0.00 %\n",
            "Accuracy of truck : 0.00 %\n"
          ]
        }
      ]
    }
  ]
}